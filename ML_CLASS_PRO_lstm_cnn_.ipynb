{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML_CLASS_PRO_lstm_cnn .ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/piyush5566/Twitter-Sentiment-Analysis/blob/master/ML_CLASS_PRO_lstm_cnn_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "va-DUeGC1Rd9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "792296cf-d3f3-4071-c1ae-382440ba2b38"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM, LeakyReLU\n",
        "from keras import optimizers\n",
        "from keras.models import load_model\n",
        "import json, argparse, os\n",
        "import re\n",
        "import io\n",
        "import sys\n",
        "from keras.layers import Conv1D, GlobalMaxPooling1D\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6kIk9ItVrb0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!wget http://nlp.stanford.edu/data/glove.6B.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GxsInIqXV-0L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!unzip glove*.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IgHaV0xJaUrB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!ls\n",
        "#!pwd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0s6GsZ3J2A3V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainDataPath = \"/content/drive/My Drive/ML CLASS PROJECT/emocontext/train.txt\"\n",
        "testDataPath = \"/content/drive/My Drive/ML CLASS PROJECT/emocontext/dev.txt\"\n",
        "\n",
        "# Path to directory where GloVe file is saved.\n",
        "gloveDir = \"/content/drive/My Drive/glove/\"\n",
        "\n",
        "NUM_FOLDS = 5                      # Value of K in K-fold Cross Validation\n",
        "NUM_CLASSES = 4                    # Number of classes - Happy, Sad, Angry, Others\n",
        "MAX_NB_WORDS = 20000                # To set the upper limit on the number of tokens extracted using keras.preprocessing.text.Tokenizer \n",
        "MAX_SEQUENCE_LENGTH = 100           # All sentences having lesser number of words than this will be padded\n",
        "EMBEDDING_DIM = 100                # The dimension of the word embeddings\n",
        "BATCH_SIZE = 200                  # The batch size to be chosen for training the model.\n",
        "LSTM_DIM = 128                    # The dimension of the representations learnt by the LSTM model\n",
        "DROPOUT = 0.2                        # Fraction of the units to drop for the linear transformation of the inputs. Ref - https://keras.io/layers/recurrent/\n",
        "NUM_EPOCHS = 20                   # Number of epochs to train a model for\n",
        "\n",
        "LEARNING_RATE = 0.003\n",
        "label2emotion = {0:\"others\", 1:\"happy\", 2: \"sad\", 3:\"angry\"}\n",
        "emotion2label = {\"others\":0, \"happy\":1, \"sad\":2, \"angry\":3}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3C9Wt1EYiGnC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "7ac7a02b-5f41-4df0-b4b3-b0ec5fc7670e"
      },
      "source": [
        "train_data = pd.read_csv(trainDataPath,sep = '\\t')\n",
        "train_data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>turn1</th>\n",
              "      <th>turn2</th>\n",
              "      <th>turn3</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Don't worry  I'm girl</td>\n",
              "      <td>hmm how do I know if you are</td>\n",
              "      <td>What's ur name?</td>\n",
              "      <td>others</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>When did I?</td>\n",
              "      <td>saw many times i think -_-</td>\n",
              "      <td>No. I never saw you</td>\n",
              "      <td>angry</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>By</td>\n",
              "      <td>by Google Chrome</td>\n",
              "      <td>Where you live</td>\n",
              "      <td>others</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>U r ridiculous</td>\n",
              "      <td>I might be ridiculous but I am telling the truth.</td>\n",
              "      <td>U little disgusting whore</td>\n",
              "      <td>angry</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Just for time pass</td>\n",
              "      <td>wt do u do 4 a living then</td>\n",
              "      <td>Maybe</td>\n",
              "      <td>others</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id                  turn1  ...                      turn3   label\n",
              "0   0  Don't worry  I'm girl  ...            What's ur name?  others\n",
              "1   1            When did I?  ...        No. I never saw you   angry\n",
              "2   2                     By  ...             Where you live  others\n",
              "3   3         U r ridiculous  ...  U little disgusting whore   angry\n",
              "4   4     Just for time pass  ...                      Maybe  others\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JfTsiC6Sihmu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "bf3b72f9-bacb-4d6f-86ec-ac8fb63321d2"
      },
      "source": [
        "train_data.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 30160 entries, 0 to 30159\n",
            "Data columns (total 5 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   id      30160 non-null  int64 \n",
            " 1   turn1   30160 non-null  object\n",
            " 2   turn2   30160 non-null  object\n",
            " 3   turn3   30160 non-null  object\n",
            " 4   label   30160 non-null  object\n",
            "dtypes: int64(1), object(4)\n",
            "memory usage: 1.2+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Buuh-PrUivWa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "9f3db9f0-5e79-4624-b2e0-177ecafeb8e5"
      },
      "source": [
        "train_data['label'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "others    14948\n",
              "angry      5506\n",
              "sad        5463\n",
              "happy      4243\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2S-50akRki42",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "outputId": "b8fc0adb-e3f5-4229-cd40-a72baca3127f"
      },
      "source": [
        "test_data = pd.read_csv(testDataPath,sep = '\\t')\n",
        "test_data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>turn1</th>\n",
              "      <th>turn2</th>\n",
              "      <th>turn3</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Then dont ask me</td>\n",
              "      <td>YOURE A GUY NOT AS IF YOU WOULD UNDERSTAND</td>\n",
              "      <td>IM NOT A GUY FUCK OFF</td>\n",
              "      <td>angry</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Mixed things  such as??</td>\n",
              "      <td>the things you do.</td>\n",
              "      <td>Have you seen minions??</td>\n",
              "      <td>others</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Today I'm very happy</td>\n",
              "      <td>and I'm happy for you ❤</td>\n",
              "      <td>I will be marry</td>\n",
              "      <td>happy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Woah bring me some</td>\n",
              "      <td>left it there oops</td>\n",
              "      <td>Brb</td>\n",
              "      <td>others</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>it is thooooo</td>\n",
              "      <td>I said soon master.</td>\n",
              "      <td>he is pressuring me</td>\n",
              "      <td>others</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id                    turn1  ...                    turn3   label\n",
              "0   0         Then dont ask me  ...    IM NOT A GUY FUCK OFF   angry\n",
              "1   1  Mixed things  such as??  ...  Have you seen minions??  others\n",
              "2   2     Today I'm very happy  ...          I will be marry   happy\n",
              "3   3       Woah bring me some  ...                      Brb  others\n",
              "4   4            it is thooooo  ...      he is pressuring me  others\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rw3f7WL5ktOZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "d44d705c-a480-464e-f49c-12d09804d142"
      },
      "source": [
        "test_data['label'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "others    2338\n",
              "angry      150\n",
              "happy      142\n",
              "sad        125\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgOSZxt82c_r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocessData(dataFilePath, mode):\n",
        "    \"\"\"Load data from a file, process and return indices, conversations and labels in separate lists\n",
        "    Input:\n",
        "        dataFilePath : Path to train/test file to be processed\n",
        "        mode : \"train\" mode returns labels. \"test\" mode doesn't return labels.\n",
        "    Output:\n",
        "        indices : Unique conversation ID list\n",
        "        conversations : List of 3 turn conversations, processed and each turn separated by the <eos> tag\n",
        "        labels :  List of labels\n",
        "    \"\"\"\n",
        "    indices = []\n",
        "    conversations = []\n",
        "    labels = []\n",
        "    with io.open(dataFilePath, encoding=\"utf8\") as finput:\n",
        "        finput.readline()\n",
        "        for line in finput:\n",
        "            # Convert multiple instances of . ? ! , to single instance\n",
        "            # okay...sure -> okay . sure\n",
        "            # okay???sure -> okay ? sure\n",
        "            # Add whitespace around such punctuation\n",
        "            # okay!sure -> okay ! sure\n",
        "            repeatedChars = ['.', '?', '!', ',']\n",
        "            for c in repeatedChars:\n",
        "                lineSplit = line.split(c)\n",
        "                while True:\n",
        "                    try:\n",
        "                        lineSplit.remove('')\n",
        "                    except:\n",
        "                        break\n",
        "                cSpace = ' ' + c + ' '    \n",
        "                line = cSpace.join(lineSplit)\n",
        "            \n",
        "            line = line.strip().split('\\t')\n",
        "            \n",
        "            label = emotion2label[line[4]]\n",
        "            labels.append(label)\n",
        "            \n",
        "            conv = ' <eos> '.join(line[1:4])\n",
        "            \n",
        "            # Remove any duplicate spaces\n",
        "            duplicateSpacePattern = re.compile(r'\\ +')\n",
        "            conv = re.sub(duplicateSpacePattern, ' ', conv)\n",
        "            \n",
        "            indices.append(int(line[0]))\n",
        "            conversations.append(conv.lower())\n",
        "    \n",
        "    \n",
        "    return indices, conversations, labels\n",
        "    \n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ynbEjMDx2ftV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getMetrics(predictions, ground):\n",
        "    \"\"\"Given predicted labels and the respective ground truth labels, display some metrics\n",
        "    Input: shape [# of samples, NUM_CLASSES]\n",
        "        predictions : Model output. Every row has 4 decimal values, with the highest belonging to the predicted class\n",
        "        ground : Ground truth labels, converted to one-hot encodings. A sample belonging to Happy class will be [0, 1, 0, 0]\n",
        "    Output:\n",
        "        accuracy : Average accuracy\n",
        "        microPrecision : Precision calculated on a micro level. Ref - https://datascience.stackexchange.com/questions/15989/micro-average-vs-macro-average-performance-in-a-multiclass-classification-settin/16001\n",
        "        microRecall : Recall calculated on a micro level\n",
        "        microF1 : Harmonic mean of microPrecision and microRecall. Higher value implies better classification  \n",
        "    \"\"\"\n",
        "    # [0.1, 0.3 , 0.2, 0.1] -> [0, 1, 0, 0]\n",
        "    discretePredictions = to_categorical(predictions.argmax(axis=1))\n",
        "    \n",
        "    truePositives = np.sum(discretePredictions*ground, axis=0)\n",
        "    falsePositives = np.sum(np.clip(discretePredictions - ground, 0, 1), axis=0)\n",
        "    falseNegatives = np.sum(np.clip(ground-discretePredictions, 0, 1), axis=0)\n",
        "    \n",
        "    print(\"True Positives per class : \", truePositives)\n",
        "    print(\"False Positives per class : \", falsePositives)\n",
        "    print(\"False Negatives per class : \", falseNegatives)\n",
        "    \n",
        "    # ------------- Macro level calculation ---------------\n",
        "    macroPrecision = 0\n",
        "    macroRecall = 0\n",
        "    # We ignore the \"Others\" class during the calculation of Precision, Recall and F1\n",
        "    for c in range(1, NUM_CLASSES):\n",
        "        precision = truePositives[c] / (truePositives[c] + falsePositives[c])\n",
        "        macroPrecision += precision\n",
        "        recall = truePositives[c] / (truePositives[c] + falseNegatives[c])\n",
        "        macroRecall += recall\n",
        "        f1 = ( 2 * recall * precision ) / (precision + recall) if (precision+recall) > 0 else 0\n",
        "        print(\"Class %s : Precision : %.3f, Recall : %.3f, F1 : %.3f\" % (label2emotion[c], precision, recall, f1))\n",
        "    \n",
        "    macroPrecision /= 3\n",
        "    macroRecall /= 3\n",
        "    macroF1 = (2 * macroRecall * macroPrecision ) / (macroPrecision + macroRecall) if (macroPrecision+macroRecall) > 0 else 0\n",
        "    print(\"Ignoring the Others class, Macro Precision : %.4f, Macro Recall : %.4f, Macro F1 : %.4f\" % (macroPrecision, macroRecall, macroF1))   \n",
        "    \n",
        "    # ------------- Micro level calculation ---------------\n",
        "    truePositives = truePositives[1:].sum()\n",
        "    falsePositives = falsePositives[1:].sum()\n",
        "    falseNegatives = falseNegatives[1:].sum()    \n",
        "    \n",
        "    print(\"Ignoring the Others class, Micro TP : %d, FP : %d, FN : %d\" % (truePositives, falsePositives, falseNegatives))\n",
        "    \n",
        "    microPrecision = truePositives / (truePositives + falsePositives)\n",
        "    microRecall = truePositives / (truePositives + falseNegatives)\n",
        "    \n",
        "    microF1 = ( 2 * microRecall * microPrecision ) / (microPrecision + microRecall) if (microPrecision+microRecall) > 0 else 0\n",
        "    # -----------------------------------------------------\n",
        "    \n",
        "    predictions = predictions.argmax(axis=1)\n",
        "    ground = ground.argmax(axis=1)\n",
        "    accuracy = np.mean(predictions==ground)\n",
        "    \n",
        "    print(\"Accuracy : %.4f, Micro Precision : %.4f, Micro Recall : %.4f, Micro F1 : %.4f\" % (accuracy, microPrecision, microRecall, microF1))\n",
        "    return accuracy, microPrecision, microRecall, microF1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHTXpGLjNqc6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getEmbeddingMatrix(wordIndex):\n",
        "    \"\"\"Populate an embedding matrix using a word-index. If the word \"happy\" has an index 19,\n",
        "       the 19th row in the embedding matrix should contain the embedding vector for the word \"happy\".\n",
        "    Input:\n",
        "        wordIndex : A dictionary of (word : index) pairs, extracted using a tokeniser\n",
        "    Output:\n",
        "        embeddingMatrix : A matrix where every row has 100 dimensional GloVe embedding\n",
        "    \"\"\"\n",
        "    embeddingsIndex = {}\n",
        "    # Load the embedding vectors from ther GloVe file\n",
        "    with io.open(os.path.join(gloveDir, 'glove.6B.100d.txt'), encoding=\"utf8\") as f:\n",
        "        for line in f:\n",
        "            values = line.split()\n",
        "            word = values[0]\n",
        "            embeddingVector = np.asarray(values[1:], dtype='float32')\n",
        "            embeddingsIndex[word] = embeddingVector\n",
        "    \n",
        "    print('Found %s word vectors.' % len(embeddingsIndex))\n",
        "    \n",
        "    # Minimum word index of any word is 1. \n",
        "    embeddingMatrix = np.zeros((len(wordIndex) + 1, EMBEDDING_DIM))\n",
        "    for word, i in wordIndex.items():\n",
        "        embeddingVector = embeddingsIndex.get(word)\n",
        "        if embeddingVector is not None:\n",
        "            # words not found in embedding index will be all-zeros.\n",
        "            embeddingMatrix[i] = embeddingVector\n",
        "    \n",
        "    return embeddingMatrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lHbE07YmN5dC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def buildModel(embeddingMatrix):\n",
        "    \"\"\"Constructs the architecture of the model\n",
        "    Input:\n",
        "        embeddingMatrix : The embedding matrix to be loaded in the embedding layer.\n",
        "    Output:\n",
        "        model : A basic LSTM model\n",
        "    \"\"\"\n",
        "    embeddingLayer = Embedding(embeddingMatrix.shape[0],\n",
        "                                EMBEDDING_DIM,\n",
        "                                weights=[embeddingMatrix],\n",
        "                                input_length=MAX_SEQUENCE_LENGTH,\n",
        "                                trainable=False)\n",
        "    model_lstm = Sequential()\n",
        "    model_lstm.add(embeddingLayer)\n",
        "    model_lstm.add(LSTM(LSTM_DIM, dropout=DROPOUT))\n",
        "    model_lstm.add(LeakyReLU())\n",
        "    model_lstm.add(Dense(64, activation = 'relu'))\n",
        "    model_lstm.add(Dense(NUM_CLASSES, activation='softmax'))\n",
        "    \n",
        "    rmsprop = optimizers.rmsprop(lr=LEARNING_RATE)\n",
        "    model_lstm.compile(loss='categorical_crossentropy',\n",
        "                  optimizer=rmsprop,\n",
        "                  metrics=['acc'])\n",
        "    \n",
        "    model_cnn = Sequential()\n",
        "    model_cnn.add(embeddingLayer)\n",
        "    model_cnn.add(Conv1D(filters=100, kernel_size=2, padding='valid', activation='relu', strides=1))\n",
        "    model_cnn.add(GlobalMaxPooling1D())\n",
        "    model_cnn.add(Dense(256, activation='relu'))\n",
        "    model_cnn.add(Dense(NUM_CLASSES, activation='softmax'))\n",
        "    model_cnn.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])\n",
        "    \n",
        "    \n",
        "    \n",
        "    return model_lstm, model_cnn\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aY8wNMCEOGeG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "4a4f7cf2-1312-4228-8c66-10c78f7eca6a"
      },
      "source": [
        "\n",
        "\n",
        "    \n",
        "        \n",
        " \n",
        "    \n",
        "    \n",
        "        \n",
        "print(\"Processing training data...\")\n",
        "trainIndices, trainTexts, labels = preprocessData(trainDataPath, mode=\"train\")\n",
        "    \n",
        "print(\"Processing test data...\")\n",
        "testIndices, testTexts, y_test = preprocessData(testDataPath, mode=\"test\")\n",
        "  \n",
        "\n",
        "print(\"Extracting tokens...\")\n",
        "tokenizer = Tokenizer(num_words=MAX_NB_WORDS)\n",
        "tokenizer.fit_on_texts(trainTexts)\n",
        "trainSequences = tokenizer.texts_to_sequences(trainTexts)\n",
        "testSequences = tokenizer.texts_to_sequences(testTexts)\n",
        "\n",
        "wordIndex = tokenizer.word_index\n",
        "print(\"Found %s unique tokens.\" % len(wordIndex))\n",
        "\n",
        "print(\"Populating embedding matrix...\")\n",
        "embeddingMatrix = getEmbeddingMatrix(wordIndex)\n",
        "\n",
        "data = pad_sequences(trainSequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "labels = to_categorical(np.asarray(labels))\n",
        "print(\"Shape of training data tensor: \", data.shape)\n",
        "print(\"Shape of label tensor: \", labels.shape)\n",
        "        \n",
        "# Randomize data\n",
        "np.random.shuffle(trainIndices)\n",
        "data = data[trainIndices]\n",
        "labels = labels[trainIndices]\n",
        "\n",
        "X_train, X_dev, y_train, y_dev = train_test_split(\n",
        "data, labels, test_size=0.10, random_state=42)\n",
        "      \n",
        "    \n",
        "         \n",
        "    \n",
        "    \n",
        "   \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing training data...\n",
            "Processing test data...\n",
            "Extracting tokens...\n",
            "Found 16831 unique tokens.\n",
            "Populating embedding matrix...\n",
            "Found 400000 word vectors.\n",
            "Shape of training data tensor:  (30160, 100)\n",
            "Shape of label tensor:  (30160, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFvCw5eqCeX5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HI7TY4aWeQeD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 904
        },
        "outputId": "597800ed-45f5-4af6-a176-2a800139f150"
      },
      "source": [
        "\n",
        "    \n",
        "        \n",
        "print(\"Building model...\")\n",
        "model_lstm,model_cnn = buildModel(embeddingMatrix)\n",
        "\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor = 'val_acc', patience = 4, restore_best_weights = True)\n",
        "\n",
        "print('Training LSTM model\\n')        \n",
        "model_lstm.fit(X_train, y_train, validation_data=(X_dev, y_dev),\n",
        "               epochs=NUM_EPOCHS, batch_size=BATCH_SIZE, callbacks = [callback])\n",
        "\n",
        "print('Training CNN model\\n')  \n",
        "        \n",
        "model_cnn.fit(X_train, y_train, validation_data=(X_dev, y_dev),\n",
        "               epochs=NUM_EPOCHS, batch_size=BATCH_SIZE, callbacks = [callback])\n",
        "\n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Building model...\n",
            "Training LSTM model\n",
            "\n",
            "Train on 27144 samples, validate on 3016 samples\n",
            "Epoch 1/20\n",
            "27144/27144 [==============================] - 22s 824us/step - loss: 0.8625 - acc: 0.6558 - val_loss: 0.6195 - val_acc: 0.7520\n",
            "Epoch 2/20\n",
            "27144/27144 [==============================] - 22s 809us/step - loss: 0.6220 - acc: 0.7619 - val_loss: 0.5563 - val_acc: 0.7822\n",
            "Epoch 3/20\n",
            "27144/27144 [==============================] - 22s 810us/step - loss: 0.5369 - acc: 0.7955 - val_loss: 0.4684 - val_acc: 0.8193\n",
            "Epoch 4/20\n",
            "27144/27144 [==============================] - 22s 812us/step - loss: 0.4721 - acc: 0.8221 - val_loss: 0.4788 - val_acc: 0.8163\n",
            "Epoch 5/20\n",
            "27144/27144 [==============================] - 22s 815us/step - loss: 0.4284 - acc: 0.8390 - val_loss: 0.4281 - val_acc: 0.8392\n",
            "Epoch 6/20\n",
            "27144/27144 [==============================] - 22s 822us/step - loss: 0.3940 - acc: 0.8503 - val_loss: 0.4372 - val_acc: 0.8269\n",
            "Epoch 7/20\n",
            "27144/27144 [==============================] - 22s 808us/step - loss: 0.3649 - acc: 0.8624 - val_loss: 0.9407 - val_acc: 0.5209\n",
            "Epoch 8/20\n",
            "27144/27144 [==============================] - 22s 805us/step - loss: 0.3709 - acc: 0.8586 - val_loss: 0.3943 - val_acc: 0.8544\n",
            "Epoch 9/20\n",
            "27144/27144 [==============================] - 22s 804us/step - loss: 0.3218 - acc: 0.8774 - val_loss: 0.4160 - val_acc: 0.8488\n",
            "Epoch 10/20\n",
            "27144/27144 [==============================] - 22s 807us/step - loss: 0.3251 - acc: 0.8778 - val_loss: 0.4085 - val_acc: 0.8465\n",
            "Epoch 11/20\n",
            "27144/27144 [==============================] - 22s 807us/step - loss: 0.2819 - acc: 0.8931 - val_loss: 0.4505 - val_acc: 0.8326\n",
            "Epoch 12/20\n",
            "27144/27144 [==============================] - 22s 796us/step - loss: 0.2684 - acc: 0.8984 - val_loss: 0.4490 - val_acc: 0.8415\n",
            "Training CNN model\n",
            "\n",
            "Train on 27144 samples, validate on 3016 samples\n",
            "Epoch 1/20\n",
            "27144/27144 [==============================] - 7s 248us/step - loss: 0.9727 - acc: 0.6098 - val_loss: 0.7491 - val_acc: 0.7178\n",
            "Epoch 2/20\n",
            "27144/27144 [==============================] - 1s 21us/step - loss: 0.6639 - acc: 0.7532 - val_loss: 0.6427 - val_acc: 0.7527\n",
            "Epoch 3/20\n",
            "27144/27144 [==============================] - 1s 21us/step - loss: 0.5900 - acc: 0.7831 - val_loss: 0.6123 - val_acc: 0.7719\n",
            "Epoch 4/20\n",
            "27144/27144 [==============================] - 1s 21us/step - loss: 0.5476 - acc: 0.7993 - val_loss: 0.6091 - val_acc: 0.7742\n",
            "Epoch 5/20\n",
            "27144/27144 [==============================] - 1s 21us/step - loss: 0.5186 - acc: 0.8109 - val_loss: 0.5826 - val_acc: 0.7898\n",
            "Epoch 6/20\n",
            "27144/27144 [==============================] - 1s 21us/step - loss: 0.4899 - acc: 0.8218 - val_loss: 0.5882 - val_acc: 0.7818\n",
            "Epoch 7/20\n",
            "27144/27144 [==============================] - 1s 21us/step - loss: 0.4677 - acc: 0.8302 - val_loss: 0.5809 - val_acc: 0.7881\n",
            "Epoch 8/20\n",
            "27144/27144 [==============================] - 1s 20us/step - loss: 0.4486 - acc: 0.8380 - val_loss: 0.5951 - val_acc: 0.7885\n",
            "Epoch 9/20\n",
            "27144/27144 [==============================] - 1s 21us/step - loss: 0.4261 - acc: 0.8455 - val_loss: 0.5963 - val_acc: 0.7878\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f359c2c94a8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zdkOX2-IlJNi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "27283d5f-6430-4f53-bbbc-5d5733a02af3"
      },
      "source": [
        "testData = pad_sequences(testSequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "    \n",
        "predictions_lstm = model_lstm.predict(testData, batch_size=BATCH_SIZE)\n",
        "predictions_lstm = predictions_lstm.argmax(axis=1)\n",
        "\n",
        "print('FOR GLOVE + LSTM')\n",
        "print(classification_report(y_test,predictions_lstm))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FOR GLOVE + LSTM\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.90      0.93      2338\n",
            "           1       0.57      0.65      0.61       142\n",
            "           2       0.49      0.74      0.59       125\n",
            "           3       0.59      0.77      0.67       150\n",
            "\n",
            "    accuracy                           0.88      2755\n",
            "   macro avg       0.65      0.77      0.70      2755\n",
            "weighted avg       0.90      0.88      0.88      2755\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJ7wdgFyEy7m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "442fa005-c077-4c94-c7f7-296366de69c1"
      },
      "source": [
        "predictions_cnn = model_cnn.predict(testData, batch_size=BATCH_SIZE)\n",
        "predictions_cnn = predictions_cnn.argmax(axis=1)\n",
        "\n",
        "print('FOR GLOVE + CNN')\n",
        "print(classification_report(y_test,predictions_cnn))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FOR GLOVE + CNN\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.87      0.91      2338\n",
            "           1       0.44      0.53      0.48       142\n",
            "           2       0.41      0.72      0.52       125\n",
            "           3       0.54      0.82      0.65       150\n",
            "\n",
            "    accuracy                           0.84      2755\n",
            "   macro avg       0.59      0.73      0.64      2755\n",
            "weighted avg       0.88      0.84      0.86      2755\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICkv3WMKMZbb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}